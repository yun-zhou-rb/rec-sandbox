{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR: Bayesian Personalized Ranking from Implicit Feedback\n",
    "\n",
    "Ref: \n",
    "* https://arxiv.org/pdf/1205.2618\n",
    "* https://medium.com/radon-dev/implicit-bayesian-personalized-ranking-in-tensorflow-b4dfa733c478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "# LOAD AND PREPARE THE DATA\n",
    "#---------------------------\n",
    "\n",
    "# Load the dataframe from a tab separated file.\n",
    "df = pd.read_csv('data/movielens/ml-latest-small/ratings.csv', sep=',')\n",
    "    \n",
    "# Add column names\n",
    "df = df.drop(df.columns[3], axis=1)\n",
    "df_movie = pd.read_csv('data/movielens/ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#users: 610, #items: 9,724 #ratings: 100,836\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop any rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop any rows with 0 rating\n",
    "df = df.loc[df.rating != 0]\n",
    "\n",
    "# Convert movies into numerical IDs\n",
    "df['user_id'] = df['userId'].astype(\"category\").cat.codes\n",
    "df['movie_id'] = df['movieId'].astype(\"category\").cat.codes\n",
    "\n",
    "# Create a lookup frame so we can get the movie\n",
    "# names back in readable form later.\n",
    "item_lookup = df[['movie_id', 'movieId']].drop_duplicates()\n",
    "item_lookup['movie_id'] = item_lookup.movie_id.astype(str)\n",
    "\n",
    "# We drop our old user and item columns\n",
    "df = df.drop(['userId', 'movieId'], axis=1)\n",
    "\n",
    "# Drop any rows with 0 rating\n",
    "df = df.loc[df.rating != 0]\n",
    "\n",
    "# Create lists of all users, movies and ratings\n",
    "users = list(np.sort(df.user_id.unique()))\n",
    "movies = list(np.sort(df.movie_id.unique()))\n",
    "ratings = list(df.rating)\n",
    "print(f\"#users: {len(users):,}, #items: {len(movies):,} #ratings: {len(ratings):,}\" )\n",
    "\n",
    "# Get the rows and columns for our new matrix\n",
    "rows = df.user_id.astype(float)\n",
    "cols = df.movie_id.astype(float)\n",
    "\n",
    "# Contruct a sparse matrix for our users and items containing number of ratings\n",
    "data_sparse = sp.csr_matrix((ratings, (rows, cols)), shape=(len(users), len(movies)))\n",
    "\n",
    "# Get the values of our matrix as a list of user ids\n",
    "# and item ids. Note that our litsts have the same length\n",
    "# as each user id repeats one time for each rated movie.\n",
    "uids, iids = data_sparse.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------\n",
    "# HYPERPARAMS\n",
    "#-------------\n",
    "\n",
    "epochs = 50\n",
    "# How many (u,i,j) triplets we sample for each batch\n",
    "samples = 150\n",
    "batches = math.ceil(uids.shape[0]/samples)\n",
    "# batches = min(batches,30)\n",
    "num_factors = 64 # Number of latent features\n",
    "\n",
    "# Independent lambda regularization values \n",
    "# for user, items and bias.\n",
    "lambda_user = 0.0000001\n",
    "lambda_item = 0.0000001\n",
    "lambda_bias = 0.0000001\n",
    "\n",
    "# Our learning rate \n",
    "lr = 0.005\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager way to iterator through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "# uids=list(range(10))\n",
    "# iids=list(range(10,20))\n",
    "# train_data = tf.data.Dataset.from_tensor_slices((uids, iids))\n",
    "# train_data = train_data.shuffle(len(uids))\n",
    "# train_data = train_data.batch(2)\n",
    "\n",
    "# for eps in range(3):\n",
    "#     batch_id = 0\n",
    "#     for x, y in train_data:\n",
    "#         print(f\"eps: {eps}, batch: {batch_id}, data: {x}, {y} \")\n",
    "#         batch_id+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# TENSORFLOW GRAPH\n",
    "#-------------------------\n",
    "\n",
    "# Set up our Tensorflow graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "def init_variable(size, dim, name=None):\n",
    "    '''\n",
    "    Helper function to initialize a new variable with\n",
    "    uniform random values.\n",
    "    '''\n",
    "    std = np.sqrt(2 / dim)\n",
    "    return tf.Variable(tf.random_uniform([size, dim], -std, std), name=name)\n",
    "\n",
    "\n",
    "def get_variable(graph, session, name):\n",
    "    '''\n",
    "    Helper function to get the value of a\n",
    "    Tensorflow variable by name.\n",
    "    '''\n",
    "    v = graph.get_operation_by_name(name)\n",
    "    v = v.values()[0]\n",
    "    v = v.eval(session=session)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 18:11:52.558595 4359620032 deprecation.py:323] From <ipython-input-9-d0e9b8e72037>:15: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with graph.as_default():\n",
    "    '''\n",
    "    Loss function: \n",
    "    -SUM ln σ(xui - xuj) + λ(w1)**2 + λ(w2)**2 + λ(w3)**2 ...\n",
    "    ln = the natural log\n",
    "    σ(xuij) = the sigmoid function of xuij.\n",
    "    λ = lambda regularization value.\n",
    "    ||W||**2 = the squared L2 norm of our model parameters.\n",
    "    \n",
    "    '''\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((uids, iids))\n",
    "    train_data = train_data.batch(samples)\n",
    "    train_data = train_data.prefetch(4)\n",
    "    iterator = train_data.make_initializable_iterator()\n",
    "    u, i = iterator.get_next()\n",
    "    j = tf.random_uniform(tf.shape(i), minval=0, maxval=len(movies), dtype=tf.int32)\n",
    "    \n",
    "    # User feature embedding\n",
    "    user_factors = init_variable(len(users), num_factors, \"user_factors\") # V matrix\n",
    "    u_factors = tf.nn.embedding_lookup(user_factors, u)\n",
    "    # Known and unknown item embeddings\n",
    "    item_factors = init_variable(len(movies), num_factors, \"item_factors\") # V matrix\n",
    "    i_factors = tf.nn.embedding_lookup(item_factors, i)\n",
    "    j_factors = tf.nn.embedding_lookup(item_factors, j)\n",
    "\n",
    "    # i and j bias embeddings.\n",
    "    item_bias = init_variable(len(movies), 1, \"item_bias\")\n",
    "    i_bias = tf.nn.embedding_lookup(item_bias, i)\n",
    "    i_bias = tf.squeeze(i_bias)\n",
    "    j_bias = tf.nn.embedding_lookup(item_bias, j)\n",
    "    j_bias = tf.squeeze(j_bias)\n",
    "\n",
    "    # Calculate the dot product + bias for known and unknown\n",
    "    # item to get xui and xuj.\n",
    "    ui = tf.reduce_sum(u_factors * i_factors, axis=1)\n",
    "    xui = i_bias + ui\n",
    "    uj = tf.reduce_sum(u_factors * j_factors, axis=1)\n",
    "    xuj = j_bias + uj\n",
    "\n",
    "    # We calculate xuij.\n",
    "    xuij = xui - xuj\n",
    "\n",
    "    # Calculate the mean AUC (area under curve).\n",
    "    # if xuij is greater than 0, that means that \n",
    "    # xui is greater than xuj (and thats what we want).\n",
    "    u_auc = tf.reduce_mean(tf.cast(xuij > 0,tf.float32))\n",
    "\n",
    "    # Output the AUC value to tensorboard for monitoring.\n",
    "    tf.summary.scalar('auc', u_auc)\n",
    "\n",
    "    # Calculate the squared L2 norm ||W||**2 multiplied by λ.\n",
    "    l2_norm = tf.add_n([\n",
    "        lambda_user * tf.reduce_sum(tf.multiply(u_factors, u_factors)),\n",
    "        lambda_item * tf.reduce_sum(tf.multiply(i_factors, i_factors)),\n",
    "        lambda_item * tf.reduce_sum(tf.multiply(j_factors, j_factors)),\n",
    "        lambda_bias * tf.reduce_sum(tf.multiply(i_bias, i_bias)),\n",
    "        lambda_bias * tf.reduce_sum(tf.multiply(j_bias, j_bias))\n",
    "        ])\n",
    "\n",
    "    # Calculate the loss as ||W||**2 - ln σ(Xuij)\n",
    "    #loss = l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(xuij)))\n",
    "    loss = -tf.reduce_mean(tf.log(tf.sigmoid(xuij))) + l2_norm\n",
    "    \n",
    "    # Train using the Adam optimizer to minimize \n",
    "    # our loss function.\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    step = opt.minimize(loss)\n",
    "\n",
    "    # Initialize all tensorflow variables.\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.030 | AUC: 1.000: 100%|██████████| 33650/33650 [00:00<00:00, 38589.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 160 ms, total: 1.51 s\n",
      "Wall time: 938 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#------------------\n",
    "# GRAPH EXECUTION\n",
    "#------------------\n",
    "\n",
    "# Run the session. \n",
    "session = tf.Session(config=None, graph=graph)\n",
    "session.run(init)\n",
    "\n",
    "# This has noting to do with tensorflow but gives\n",
    "# us a nice progress bar for the training.\n",
    "progress = tqdm(total=batches*epochs)\n",
    "idx=np.arange(uids.shape[0])\n",
    "for _ in range(epochs):\n",
    "    session.run(iterator.initializer)\n",
    "\n",
    "    # We run the session.\n",
    "    _, l, auc = session.run([step, loss, u_auc])\n",
    "    progress.update(batches)\n",
    "    progress.set_description('Loss: %.3f | AUC: %.3f' % (l, auc))\n",
    "\n",
    "progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
